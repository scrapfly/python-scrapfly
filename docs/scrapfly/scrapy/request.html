<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>scrapfly.scrapy.request API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>scrapfly.scrapy.request</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from copy import deepcopy
from typing import Dict, Optional

from scrapy import Request

from .. import ScrapeConfig


class ScrapflyScrapyRequest(Request):
    scrape_config: ScrapeConfig

    # See request_from_dict method in scrapy.utils.request
    attributes = tuple(
        attr for attr in Request.attributes if attr not in [&#34;body&#34;, &#34;cookies&#34;, &#34;headers&#34;, &#34;method&#34;, &#34;url&#34;]) + (
                 &#34;scrape_config&#34;,)

    # url:str   inherited
    # method:str inherited
    # body:bytes inherited
    # headers:Dict inherited
    # encoding:Dict inherited

    def __init__(self, scrape_config: ScrapeConfig, meta: Dict = {}, *args, **kwargs):
        self.scrape_config = scrape_config

        meta[&#39;scrapfly_scrape_config&#39;] = self.scrape_config

        super().__init__(
            *args,
            url=self.scrape_config.url,
            headers=self.scrape_config.headers,
            cookies=self.scrape_config.cookies,
            body=self.scrape_config.body,
            meta=meta,
            **kwargs
        )

    def to_dict(self, *, spider: Optional[&#34;scrapy.Spider&#34;] = None) -&gt; dict:
        if spider is None:
            raise ValueError(&#34;The &#39;spider&#39; argument is required to serialize the request.&#34;)
        d = super().to_dict(spider=spider)
        d[&#39;scrape_config&#39;] = self.scrape_config
        return d

    @classmethod
    def from_dict(cls, data):
        scrape_config_data = data[&#39;meta&#39;][&#39;scrapfly_scrape_config&#39;].to_dict()
        scrape_config = ScrapeConfig.from_dict(scrape_config_data)
        request = cls(scrape_config=scrape_config)
        return request

    def replace(self, *args, **kwargs):
        for x in [
            &#39;meta&#39;,
            &#39;flags&#39;,
            &#39;encoding&#39;,
            &#39;priority&#39;,
            &#39;dont_filter&#39;,
            &#39;callback&#39;,
            &#39;errback&#39;,
            &#39;cb_kwargs&#39;,
        ]:
            kwargs.setdefault(x, getattr(self, x))
            kwargs[&#39;scrape_config&#39;] = deepcopy(self.scrape_config)

        cls = kwargs.pop(&#39;cls&#39;, self.__class__)
        return cls(*args, **kwargs)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="scrapfly.scrapy.request.ScrapflyScrapyRequest"><code class="flex name class">
<span>class <span class="ident">ScrapflyScrapyRequest</span></span>
<span>(</span><span>scrape_config: <a title="scrapfly.scrape_config.ScrapeConfig" href="../scrape_config.html#scrapfly.scrape_config.ScrapeConfig">ScrapeConfig</a>, meta: Dict = {}, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Represents an HTTP request, which is usually generated in a Spider and
executed by the Downloader, thus generating a :class:<code>Response</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ScrapflyScrapyRequest(Request):
    scrape_config: ScrapeConfig

    # See request_from_dict method in scrapy.utils.request
    attributes = tuple(
        attr for attr in Request.attributes if attr not in [&#34;body&#34;, &#34;cookies&#34;, &#34;headers&#34;, &#34;method&#34;, &#34;url&#34;]) + (
                 &#34;scrape_config&#34;,)

    # url:str   inherited
    # method:str inherited
    # body:bytes inherited
    # headers:Dict inherited
    # encoding:Dict inherited

    def __init__(self, scrape_config: ScrapeConfig, meta: Dict = {}, *args, **kwargs):
        self.scrape_config = scrape_config

        meta[&#39;scrapfly_scrape_config&#39;] = self.scrape_config

        super().__init__(
            *args,
            url=self.scrape_config.url,
            headers=self.scrape_config.headers,
            cookies=self.scrape_config.cookies,
            body=self.scrape_config.body,
            meta=meta,
            **kwargs
        )

    def to_dict(self, *, spider: Optional[&#34;scrapy.Spider&#34;] = None) -&gt; dict:
        if spider is None:
            raise ValueError(&#34;The &#39;spider&#39; argument is required to serialize the request.&#34;)
        d = super().to_dict(spider=spider)
        d[&#39;scrape_config&#39;] = self.scrape_config
        return d

    @classmethod
    def from_dict(cls, data):
        scrape_config_data = data[&#39;meta&#39;][&#39;scrapfly_scrape_config&#39;].to_dict()
        scrape_config = ScrapeConfig.from_dict(scrape_config_data)
        request = cls(scrape_config=scrape_config)
        return request

    def replace(self, *args, **kwargs):
        for x in [
            &#39;meta&#39;,
            &#39;flags&#39;,
            &#39;encoding&#39;,
            &#39;priority&#39;,
            &#39;dont_filter&#39;,
            &#39;callback&#39;,
            &#39;errback&#39;,
            &#39;cb_kwargs&#39;,
        ]:
            kwargs.setdefault(x, getattr(self, x))
            kwargs[&#39;scrape_config&#39;] = deepcopy(self.scrape_config)

        cls = kwargs.pop(&#39;cls&#39;, self.__class__)
        return cls(*args, **kwargs)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>scrapy.http.request.Request</li>
<li>scrapy.utils.trackref.object_ref</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="scrapfly.scrapy.request.ScrapflyScrapyRequest.attributes"><code class="name">var <span class="ident">attributes</span> : Tuple[str, ...]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="scrapfly.scrapy.request.ScrapflyScrapyRequest.scrape_config"><code class="name">var <span class="ident">scrape_config</span> : <a title="scrapfly.scrape_config.ScrapeConfig" href="../scrape_config.html#scrapfly.scrape_config.ScrapeConfig">ScrapeConfig</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="scrapfly.scrapy.request.ScrapflyScrapyRequest.from_dict"><code class="name flex">
<span>def <span class="ident">from_dict</span></span>(<span>data)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_dict(cls, data):
    scrape_config_data = data[&#39;meta&#39;][&#39;scrapfly_scrape_config&#39;].to_dict()
    scrape_config = ScrapeConfig.from_dict(scrape_config_data)
    request = cls(scrape_config=scrape_config)
    return request</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="scrapfly.scrapy.request.ScrapflyScrapyRequest.replace"><code class="name flex">
<span>def <span class="ident">replace</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a new Request with the same attributes except for those given new values</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def replace(self, *args, **kwargs):
    for x in [
        &#39;meta&#39;,
        &#39;flags&#39;,
        &#39;encoding&#39;,
        &#39;priority&#39;,
        &#39;dont_filter&#39;,
        &#39;callback&#39;,
        &#39;errback&#39;,
        &#39;cb_kwargs&#39;,
    ]:
        kwargs.setdefault(x, getattr(self, x))
        kwargs[&#39;scrape_config&#39;] = deepcopy(self.scrape_config)

    cls = kwargs.pop(&#39;cls&#39;, self.__class__)
    return cls(*args, **kwargs)</code></pre>
</details>
</dd>
<dt id="scrapfly.scrapy.request.ScrapflyScrapyRequest.to_dict"><code class="name flex">
<span>def <span class="ident">to_dict</span></span>(<span>self, *, spider: Optional[ForwardRef('scrapy.Spider')] = None) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><p>Return a dictionary containing the Request's data.</p>
<p>Use :func:<code>~scrapy.utils.request.request_from_dict</code> to convert back into a :class:<code>~scrapy.Request</code> object.</p>
<p>If a spider is given, this method will try to find out the name of the spider methods used as callback
and errback and include them in the output dict, raising an exception if they cannot be found.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_dict(self, *, spider: Optional[&#34;scrapy.Spider&#34;] = None) -&gt; dict:
    if spider is None:
        raise ValueError(&#34;The &#39;spider&#39; argument is required to serialize the request.&#34;)
    d = super().to_dict(spider=spider)
    d[&#39;scrape_config&#39;] = self.scrape_config
    return d</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="scrapfly.scrapy" href="index.html">scrapfly.scrapy</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="scrapfly.scrapy.request.ScrapflyScrapyRequest" href="#scrapfly.scrapy.request.ScrapflyScrapyRequest">ScrapflyScrapyRequest</a></code></h4>
<ul class="">
<li><code><a title="scrapfly.scrapy.request.ScrapflyScrapyRequest.attributes" href="#scrapfly.scrapy.request.ScrapflyScrapyRequest.attributes">attributes</a></code></li>
<li><code><a title="scrapfly.scrapy.request.ScrapflyScrapyRequest.from_dict" href="#scrapfly.scrapy.request.ScrapflyScrapyRequest.from_dict">from_dict</a></code></li>
<li><code><a title="scrapfly.scrapy.request.ScrapflyScrapyRequest.replace" href="#scrapfly.scrapy.request.ScrapflyScrapyRequest.replace">replace</a></code></li>
<li><code><a title="scrapfly.scrapy.request.ScrapflyScrapyRequest.scrape_config" href="#scrapfly.scrapy.request.ScrapflyScrapyRequest.scrape_config">scrape_config</a></code></li>
<li><code><a title="scrapfly.scrapy.request.ScrapflyScrapyRequest.to_dict" href="#scrapfly.scrapy.request.ScrapflyScrapyRequest.to_dict">to_dict</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>